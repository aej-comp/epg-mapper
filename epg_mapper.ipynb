{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## m3u playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load playlist\n",
    "df = pd.read_csv('./playlist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add here urls to your epg services\n",
    "epg_urls = ['https://epgshare01.online/epgshare01/epg_ripper_DE1.txt',\n",
    "            'https://epgshare01.online/epgshare01/epg_ripper_US1.txt',\n",
    "            'https://epgshare01.online/epgshare01/epg_ripper_UK1.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response_combined = []\n",
    "\n",
    "for url in epg_urls:\n",
    "    print(f'Fetching {url}')\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_combined.append(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two responses\n",
    "response_combined = '\\n'.join(response_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list\n",
    "epg_data = response_combined.split('\\n')\n",
    "\n",
    "# remove empty lines\n",
    "epg_data = [line for line in epg_data if line]\n",
    "\n",
    "epg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find epg entries (using LLM and AWS Bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bedrock Runtime client in the AWS Region you want to use.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Set the model ID, e.g., Amazon Nova Lite.\n",
    "model_id = \"amazon.nova-lite-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_response(client, model_id, epg_data, channel, country):\n",
    "\n",
    "    user_message = f'''\n",
    "        You are given a tv channel list and a channel name. \n",
    "        You provide the closest match to the channel name from the list.\n",
    "\n",
    "        Tv channel list: {epg_data}\n",
    "        Channel name: {channel}\n",
    "        Country: {country}\n",
    "\n",
    "        Firstly explain your response, followed by your final answer. You should follow the format \n",
    "        Explanation: [Explanation], Answer: [Answer],\n",
    "\n",
    "        where [Answer] can be one entry from the tv channel list or \"no match\". \n",
    "    '''\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": user_message}],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Send the message to the model, using a basic inference configuration.\n",
    "        response = client.converse(\n",
    "            modelId=model_id,\n",
    "            messages=conversation,\n",
    "            inferenceConfig={\"maxTokens\": 512, \"temperature\": 0, \"topP\": 0.5},\n",
    "        )\n",
    "\n",
    "        # Extract and print the response text.\n",
    "        response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "        #print(response_text)\n",
    "\n",
    "        # extract the last line\n",
    "        response = response_text.split('\\n')[-1].strip()\n",
    "\n",
    "        # extract entry after :\n",
    "        response = response.split(':')[-1].strip()\n",
    "\n",
    "        # remove any ' or \" characters\n",
    "        response = response.replace(\"'\", \"\")\n",
    "        response = response.replace('\"', \"\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epg_ids = []\n",
    "\n",
    "for ix, row in df.iterrows():\n",
    "\n",
    "    ch = row['Channel Name']\n",
    "    country = row['Country']\n",
    "    \n",
    "    response = llm_response(client, model_id, epg_data, ch, country)\n",
    "    print(ch, response)\n",
    "\n",
    "    if (response != \"no match\"):\n",
    "        epg_ids.append((ch,response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to tvg id column based on first tuple entry\n",
    "df['TVG ID'] = df['Channel Name'].map(dict(epg_ids))\n",
    "\n",
    "# fill entries where no match has found \n",
    "df['TVG ID'] = df['TVG ID'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check empty TVG ID\n",
    "mask = df['TVG ID'] == ''\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to an M3U formatted file\n",
    "m3u_file_path = \"playlist.m3u\"\n",
    "\n",
    "with open(m3u_file_path, \"w\") as f:\n",
    "    f.write(\"#EXTM3U\\n\")\n",
    "    for _, row in df.iterrows():\n",
    "        f.write(f'#EXTINF:-1 tvg-chno=\"{row[\"TVG Channel Number\"]}\" tvg-id=\"{row[\"TVG ID\"]}\" tvg-name=\"{row[\"TVG Name\"]}\" tvg-logo=\"{row[\"TVG Logo\"]}\" group-title=\"{row[\"Group Title\"]}\",{row[\"Channel Name\"]}\\n')\n",
    "        f.write(f'{row[\"Stream URL\"]}\\n')\n",
    "\n",
    "print(f\"M3U8 file saved as {m3u_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
